---
title: "FATE summary results"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Rcpp)
library(ewidata)
library(knitr)
library(reshape2)
library(rstan)
library(tibble)
library(dplyr)
library(gtools)
library(bayesdfa)
library(assertthat)
library(rstanarm)
library(tidyverse)
```

## Results

This is the initial write-up on results for the FATE paper.

### Climate

The best model for GOA climate was the two-trend, independent error model. Trend one positively loaded SST and the Papa advection index, and negatively loaded GAK1 20m salinity. Trend two negatively loaded the upwelling indices and positively loaded the SLP gradient (Fig. 1A). 

#### Fig. 1A
GOA climate trend loadings.

```{r, echo=F}

GOA.clim <- readRDS("GOA_clim_2_trends_original_data.rds") # read in GOA climate model

# recover the years and names for plots!
goa.clim <- read.csv("updated goa climate data.csv")

sub_data <- goa.clim %>%
  select(-ssh, -wind.stress) %>%
  gather(key="code", value="value", -year)

melted = melt(sub_data[, c("code", "year", "value")], id.vars = c("code", "year"))
Y <- dcast(melted, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])

rotated = rotate_trends(GOA.clim$best_model) 

# set new names
new.names <- c("East spring SST", "East winter SST", "SLP gradient", "Papa advection", "GAK1 salinity", "West spring SST", "West winter SST", " Upwell 54 134", " Upwell 57 137", " Upwell 60 146", " Upwell 60 149")


# bespoke plotting code
loadings.1 <- as.data.frame(rotated$Z_rot[,,1])
loadings.2 <- as.data.frame(rotated$Z_rot[,,2])
names(loadings.1) <- names(loadings.2) <- names

# drop columns that don't meet threshold
thresh <- 0.9

f <- function(x) max(sum(x<0)/length(x), sum(x>0)/length(x))
  
prop1 <- apply(loadings.1, 2, f)
prop2 <- apply(loadings.2, 2, f)  

# so! only Trend 1 includes loadings > 0.9! 
# this justifies fitting/retaining only a 1-trend model!

# load the 1-trend object
GOA.clim <- readRDS("GOA_clim_1_trend_original_data.rds") # read in GOA climate model

# recover the years and names for plots!
goa.clim <- read.csv("updated goa climate data.csv")

sub_data <- goa.clim %>%
  select(-ssh, -wind.stress) %>%
  gather(key="code", value="value", -year)

melted = melt(sub_data[, c("code", "year", "value")], id.vars = c("code", "year"))
Y <- dcast(melted, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])

rotated = rotate_trends(GOA.clim$best_model) 


plot.trend <- data.frame(year=1950:2019, trend=as.vector(rotated$trends_mean),
                         lo=as.vector(rotated$trends_lower),
                         hi=as.vector(rotated$trends_upper))

# set palette
cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

plot.b <- ggplot(plot.trend, aes(year, trend)) +
  theme_bw() +
  geom_line(color=cb[3]) +
  geom_ribbon(aes(ymin=lo, ymax=hi), fill=cb[3], alpha=0.4) +
  geom_hline(yintercept = 0) + ylab("Trend value") + xlab("Year") +
  ggtitle("b) Trend")

png("combined GOA climate loading and trend plot.png", 6, 3, units = "in", res=300)

ggpubr::ggarrange(plot.a, plot.b, ncol=2)

dev.off()

# back to the bespoke code!
loadings.1 <- as.data.frame(rotated$Z_rot[,,1])
names(loadings.1)  <- new.names

# drop columns that don't meet threshold
# first, figure out the proportion above/below 0
f <- function(x) max(sum(x<0)/length(x), sum(x>0)/length(x))
  
prop1 <- apply(loadings.1, 2, f)
prop1
keep <- prop1 > 0.90

loadings.1 <- loadings.1[,keep]

# plot
plot.load <- loadings.1 %>%
  gather()

rank <- tapply(plot.load$value, plot.load$key, mean)
plot.load$rank <- rank[match(plot.load$key, names(rank))]
  
plot.load$key <- reorder(plot.load$key, plot.load$rank)

# set pallette
cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

plot.a <- ggplot(plot.load, aes(key, value)) +
  theme_bw() +
  geom_violin(fill=cb[3], color=NA) +
  geom_hline(yintercept = 0) +
  theme(axis.title.y = element_blank()) + ylab("Loading") +
  coord_flip() +
  ggtitle("a) Loadings") +
  ylim(-2,2)

modelfit <- GOA.clim$best_model

  n_ts <- dim(modelfit$data)[1]
  n_years <- dim(modelfit$data)[2]
  pred <- predicted(modelfit)
   res.df <- data.frame(ID = rep(seq_len(n_ts),
                                 n_years),
                        Time = sort(rep(seq_len(n_years), n_ts)), 
                        mean = c(t(apply(pred, c(3, 4), mean))), 
                        lo = c(t(apply(pred, c(3, 4), quantile, 0.025))),
                        hi = c(t(apply(pred, c(3, 4), quantile, 0.975))), 
                        y = c(modelfit$data)) 
  
        res.df$ID <- new.names
  
   
  res.df$year <-  rep(1950:2019, each=n_ts)   
  
  res.df$mean.res <- res.df$y - res.df$mean
  res.df$lo.res <- res.df$y - res.df$lo
  res.df$hi.res <- res.df$y - res.df$hi
  
 plot.these <- names(keep)[keep] 
  
 res.df <- res.df %>%
   filter(ID %in% plot.these)
 
  ggplot(res.df, aes_string(x = "year", y = "mean.res")) + geom_ribbon(aes_string(ymin = "lo.res", 
        ymax = "hi.res"), fill=cb[3], alpha = 0.4) + geom_line(color=cb[3]) + facet_wrap("ID", 
        scales = "free_y") + xlab("Year") + ylab("") + geom_hline(yintercept = 0, col=cb[2]) +
        geom_vline(xintercept = c(1988.5, 2014), lty=2)


    
# acf plot
    index <- unique(res.df$ID)
  
    par(mfrow=c(2,4))
    for(i in 1:length(index)){
     # i <- 1
      temp <- res.df %>%
        filter(ID==index[i])
      temp <- na.omit(temp)
      acf(temp$mean.res, main=index[i]) 
    }

# so...no autocorrelation concerns with residuals   
    
# look at rolling correlations between fitted and observed values, as in Ecology paper
# using 25-yr rolling windows!

    dfa.cor <- data.frame()    

    for(i in 1:length(index)){    
      # i <- 1 
      temp <- res.df %>%
        filter(ID==index[i])
      
       for(ii in 13:58){
       #  ii <- 13
          win <- temp[(ii-12):(ii+12),]
          temp.cor <- data.frame(ID=unique(win$ID),
                                 year=win$year[13], 
                                 window=25,
                                 mean.cor=cor(win$y, win$mean, use="p"),
                                 n.cor=sum(!is.na(win$y)))
          dfa.cor <- rbind(dfa.cor, temp.cor)
       }  }


# now the 11-yr windows
     for(i in 1:length(index)){    
      # i <- 1 
      temp <- res.df %>%
        filter(ID==index[i])
             for(ii in 6:65){
       #  ii <- 13
          win <- temp[(ii-5):(ii+5),]
          temp.cor <- data.frame(ID=unique(win$ID),
                                 year=win$year[6],
                                 window=11,
                                 mean.cor=cor(win$y, win$mean, use="p"),
                                 n.cor=sum(!is.na(win$y)))
          dfa.cor <- rbind(dfa.cor, temp.cor)
             }  }
      
      # and the 15-yr windows
    for(i in 1:length(index)){    
      # i <- 1 
      temp <- res.df %>%
        filter(ID==index[i])
      
             for(ii in 8:63){
       #  ii <- 13
          win <- temp[(ii-7):(ii+7),]
          temp.cor <- data.frame(ID=unique(win$ID),
                                 year=win$year[8],
                                 window=15,
                                 mean.cor=cor(win$y, win$mean, use="p"),
                                 n.cor=sum(!is.na(win$y)))
          dfa.cor <- rbind(dfa.cor, temp.cor)
       }  }
    
# remove salinity correlations with < 10 obs
dfa.cor <- dfa.cor %>%
  filter(n.cor>=10)
 dfa.cor$window <- as.factor(dfa.cor$window) 
 
ggplot(dfa.cor, aes(year, mean.cor, color=window)) + 
  theme_bw() + theme(axis.title.x = element_blank()) +
  geom_line() + facet_wrap(~ID, 
        scales = "free_y") + xlab("Year") + ylab("Correlation") 

ggsave("goa climate dfa correlations 11 15 25 year windows.png", height = 4, width=6, units="in")

# and plot 15-yr windows
ggplot(filter(dfa.cor, window==15), aes(year, mean.cor)) + 
  theme_bw() + theme(axis.title.x = element_blank()) +
  geom_line(color=cb[3]) + facet_wrap(~ID, 
        scales = "free_y") + xlab("Year") + ylab("Correlation") 

ggsave("goa climate dfa correlations 15 year windows.png", height = 4, width=6, units="in")


# and plot 25-yr windows
ggplot(filter(dfa.cor, window==25), aes(year, mean.cor)) + 
  theme_bw() + theme(axis.title.x = element_blank()) +
  geom_line(color=cb[3]) + facet_wrap(~ID, 
        scales = "free_y") + xlab("Year") + ylab("Correlation") 

ggsave("goa climate dfa correlations 25 year windows.png", height = 4, width=6, units="in")

# re-run with al climate TS, not just the ones meeting the loadings threshold used above

# set up res.df with all TS
   res.df <- data.frame(ID = rep(seq_len(n_ts),
                                 n_years),
                        Time = sort(rep(seq_len(n_years), n_ts)), 
                        mean = c(t(apply(pred, c(3, 4), mean))), 
                        lo = c(t(apply(pred, c(3, 4), quantile, 0.025))),
                        hi = c(t(apply(pred, c(3, 4), quantile, 0.975))), 
                        y = c(modelfit$data)) 
  
        res.df$ID <- new.names
  
   
  res.df$year <-  rep(1950:2019, each=n_ts)   
  
  res.df$mean.res <- res.df$y - res.df$mean
  res.df$lo.res <- res.df$y - res.df$lo
  res.df$hi.res <- res.df$y - res.df$hi

# look at rolling correlations between fitted and observed values, as in Ecology paper
# using 25-yr rolling windows!
 index <- unique(res.df$ID)
    dfa.cor <- data.frame()    

    for(i in 1:length(index)){    
      # i <- 1 
      temp <- res.df %>%
        filter(ID==index[i])
      
       for(ii in 13:58){
       #  ii <- 13
          win <- temp[(ii-12):(ii+12),]
          temp.cor <- data.frame(ID=unique(win$ID),
                                 year=win$year[13], 
                                 window=25,
                                 mean.cor=cor(win$y, win$mean, use="p"),
                                 n.cor=sum(!is.na(win$y)))
          dfa.cor <- rbind(dfa.cor, temp.cor)
       }  }
    
# remove salinity correlations with < 10 obs
dfa.cor <- dfa.cor %>%
  filter(n.cor>=10)
 dfa.cor$window <- as.factor(dfa.cor$window) 

ggplot(filter(dfa.cor, window==25), aes(year, mean.cor)) + 
  theme_bw() + theme(axis.title.x = element_blank()) +
  geom_line(color=cb[3]) + facet_wrap(~ID, 
        scales = "free_y", ncol=3) + xlab("Year") + ylab("Correlation") 

ggsave("goa climate dfa correlations 25 year windows all TS.png", height = 5, width=6, units="in")    
```

### Fig. 1B
GOA climate trends

```{r, echo=F}
# trends
# plot.trend <- data.frame(year=1972:2017, trend=as.vector(rotated$trends_mean),
#                          lo=as.vector(rotated$trends_lower),
#                          hi=as.vector(rotated$trends_upper))
# 
# plot.b <- ggplot(plot.trend, aes(year, trend)) +
#   theme_bw() +
#   geom_line(color=cb[3]) +
#   geom_ribbon(aes(ymin=lo, ymax=hi), fill=cb[3], alpha=0.4) +
#   geom_hline(yintercept = 0) + ylab("Trend value") +
#   theme(axis.title.x = element_blank()) + 
#   ggtitle("b) Trend")
# 
# png("combined GOA climate loading and trend plot.png", 8, 4, units = "in", res=300)
# 
# ggpubr::ggarrange(plot.a, plot.b, ncol=2)
# 
# dev.off()
```

Find swans.

```{r, echo=F}
xx <- find_swans(rotated, threshold = 0.01, plot=F)
xx$year <- 1950:2019
xx <- filter(xx, below_threshold == T)
xx
```

Test for regime probability. Use n=5 maximum states.

```{r, include=F}

y = apply(rotated$trends, c(2,3), mean)
sd_y = apply(rotated$trends, c(2,3), sd)

# run each trend sequentially through the regimes
# code to identify (1) number of changes and (2)
# where those change points occur.
set.seed(99)
f1 = find_regimes(y = y[1,], sds = sd_y[1,], max_regimes = 5)

# # repeat with 2nd and third trends, e.g.
# set.seed(99)
# f2 = find_regimes(y = y[2,], sds = sd_y[2,], max_regimes = 3)
# 
# # # repeat with 2nd and third trends, e.g.
# set.seed(99)
# f3 = find_regimes(y = y[3,], sds = sd_y[3,], max_regimes = 3)
```

Regime results for Trend 1. The 2-regime model is best-supported, no evidence at this point for a switch to a novel, warmer state.

 
```{r, echo=F}
print(f1$table) # this shows 2-regime model is best
plot_regime_model(f1$best_model)
```

```{r}
# try to extract annual P of each state!

kk <- plot_regime_model(f1$best_model, plot_prob_indices=c(2))

clim.regimes <- data.frame(year=1950:2019, probability=kk$data$median, lwr=kk$data$lwr, upr=kk$data$upr)

ggplot(clim.regimes, aes(year, probability)) +
  theme_bw() +
  geom_line()
  
# may be promising to plot all of the regime results together!

clim.regimes$data.set <- "Climate 1950-2019"
```


## GOA biology results.

One trend model was the best.

```{r, echo=F}
GOA.biol <- readRDS("GOA_biol_11.4.19.rds") 
GOA.biol$summary
```

### Fig. 2A

```{r, echo=F}

# reload the version of data used
GOA <- read.csv("updated GOA biology data.csv")

# recover the years and names for plots!
sub_data = GOA

melted = melt(sub_data[, c("code", "year", "value")], id.vars = c("code", "year"))
Y <- dcast(melted, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])

rotated = rotate_trends(GOA.biol$best_model) 

new.names <- c("Chignik.coho", "Chignik.pink", "Chiniak.eulachon", "Chiniak.jellyfish", "Chiniak.P.cod", "Chiniak.shrimp", "Cook.Inlet.coho", "Kodiak.coho", "Kodiak.pink", "Pavlof.capelin", "Pavlof.eulachon", "Pavlof.jellyfish", "Pavlof.P.cod", "Pavlof.shrimp", "Prince.William.coho", "Southeast.coho", "Southeast.herring", "Southeast.pink", "South.Peninsula.coho", "South.Peninsula.pink")

 check <- data.frame(names=names, newnames=new.names)
 check

 # back to the bespoke code!
loadings.1 <- as.data.frame(rotated$Z_rot[,,1])
names(loadings.1)  <- new.names

# drop columns that don't meet threshold
# first, figure out the proportion above/below 0
f <- function(x) max(sum(x<0)/length(x), sum(x>0)/length(x))
  
prop1 <- apply(loadings.1, 2, f)
prop1
keep <- prop1 > 0.9 # changed threshold to 0.9

loadings.1 <- loadings.1[,keep]

# plot
plot.load <- loadings.1 %>%
  gather()

rank <- tapply(plot.load$value, plot.load$key, mean)
plot.load$rank <- rank[match(plot.load$key, names(rank))]
  
plot.load$key <- reorder(plot.load$key, plot.load$rank)

# set pallette
cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

plot.a <- ggplot(plot.load, aes(key, value)) +
  theme_bw() +
  geom_violin(fill=cb[3], color=NA) +
  geom_hline(yintercept = 0) +
  theme(axis.title.y = element_blank()) + ylab("Loading") +
  coord_flip() + ylim(-1.5, 1.5) +
  ggtitle("a) Loadings")
```


```{r, echo=F}
# trends
plot.trend <- data.frame(year=1972:2019, trend=as.vector(rotated$trends_mean),
                         lo=as.vector(rotated$trends_lower),
                         hi=as.vector(rotated$trends_upper))

plot.b <- ggplot(plot.trend, aes(year, trend)) +
  theme_bw() +
  geom_line(color=cb[3]) +
  geom_ribbon(aes(ymin=lo, ymax=hi), fill=cb[3], alpha=0.4) +
  geom_hline(yintercept = 0) + ylab("Trend value") +
  xlab("Year") + 
  ggtitle("b) Trend")

png("combined GOA biology loading and trend plot.png", 8, 4, units = "in", res=300)

ggpubr::ggarrange(plot.a, plot.b, ncol=2)

dev.off()
```

```{r, echo=F}
# look at rolling correlations between fitted and observed values, as in Ecology paper
modelfit <- GOA.biol$best_model

  n_ts <- dim(modelfit$data)[1]
  n_years <- dim(modelfit$data)[2]
  pred <- predicted(modelfit)
   res.df <- data.frame(ID = rep(seq_len(n_ts),
                                 n_years),
                        Time = sort(rep(seq_len(n_years), n_ts)), 
                        mean = c(t(apply(pred, c(3, 4), mean))), 
                        lo = c(t(apply(pred, c(3, 4), quantile, 0.025))),
                        hi = c(t(apply(pred, c(3, 4), quantile, 0.975))), 
                        y = c(modelfit$data)) 
  
        res.df$ID <- new.names
  
   
  res.df$year <-  rep(1972:2017, each=n_ts)   
  
  res.df$mean.res <- res.df$y - res.df$mean
  res.df$lo.res <- res.df$y - res.df$lo
  res.df$hi.res <- res.df$y - res.df$hi
  
 plot.these <- names(keep)[keep] 
  
 res.df <- res.df %>%
   filter(ID %in% plot.these)
 
  ggplot(res.df, aes_string(x = "year", y = "mean.res")) + geom_ribbon(aes_string(ymin = "lo.res", 
        ymax = "hi.res"), fill=cb[3], alpha = 0.4) + geom_line(color=cb[3]) + facet_wrap("ID", 
        scales = "free_y") + xlab("Year") + ylab("") + geom_hline(yintercept = 0, col=cb[2]) +
        geom_vline(xintercept = c(1988.5, 2014), lty=2)


    
# acf plot
    index <- unique(res.df$ID)
  
    par(mfrow=c(2,4))
    for(i in 1:length(index)){
     # i <- 1
      temp <- res.df %>%
        filter(ID==index[i])
      temp <- na.omit(temp)
      acf(temp$mean.res, main=index[i]) 
    }
# using 25-yr rolling windows!

    dfa.cor <- data.frame()    

    for(i in 1:length(index)){    
      # i <- 1 
      temp <- res.df %>%
        filter(ID==index[i])
      
       for(ii in 13:58){
       #  ii <- 13
          win <- temp[(ii-12):(ii+12),]
          temp.cor <- data.frame(ID=unique(win$ID),
                                 year=win$year[13], 
                                 window=25,
                                 mean.cor=cor(win$y, win$mean, use="p"),
                                 n.cor=sum(!is.na(win$y)))
          dfa.cor <- rbind(dfa.cor, temp.cor)
       }  }


# now the 11-yr windows
     for(i in 1:length(index)){    
      # i <- 1 
      temp <- res.df %>%
        filter(ID==index[i])
             for(ii in 6:65){
       #  ii <- 13
          win <- temp[(ii-5):(ii+5),]
          temp.cor <- data.frame(ID=unique(win$ID),
                                 year=win$year[6],
                                 window=11,
                                 mean.cor=cor(win$y, win$mean, use="p"),
                                 n.cor=sum(!is.na(win$y)))
          dfa.cor <- rbind(dfa.cor, temp.cor)
             }  }
      
      # and the 15-yr windows
    for(i in 1:length(index)){    
      # i <- 1 
      temp <- res.df %>%
        filter(ID==index[i])
      
             for(ii in 8:63){
       #  ii <- 13
          win <- temp[(ii-7):(ii+7),]
          temp.cor <- data.frame(ID=unique(win$ID),
                                 year=win$year[8],
                                 window=15,
                                 mean.cor=cor(win$y, win$mean, use="p"),
                                 n.cor=sum(!is.na(win$y)))
          dfa.cor <- rbind(dfa.cor, temp.cor)
       }  }
    
# remove correlations with < 10 obs
dfa.cor <- dfa.cor %>%
  filter(n.cor>=10)
 dfa.cor$window <- as.factor(dfa.cor$window) 
 
dfa.cor <- na.omit(dfa.cor)
  
ggplot(dfa.cor, aes(year, mean.cor, color=window)) + 
  theme_bw() + theme(axis.title.x = element_blank()) +
  geom_line() + facet_wrap(~ID, 
        scales = "free_y") + xlab("Year") + ylab("Correlation") 

ggsave("goa biology dfa correlations 11 15 25 year windows.png", height = 4, width=6, units="in")

# and plot 15-yr windows
ggplot(filter(dfa.cor, window==15), aes(year, mean.cor)) + 
  theme_bw() + theme(axis.title.x = element_blank()) +
  geom_path(color=cb[3]) + geom_point(color=cb[3]) + facet_wrap(~ID, 
        scales = "free_y") + xlab("Year") + ylab("Correlation") 

ggsave("goa biology dfa correlations 15 year windows.png", height = 4, width=6, units="in")


# and plot 25-yr windows
ggplot(filter(dfa.cor, window==25), aes(year, mean.cor)) + 
  theme_bw() + theme(axis.title.x = element_blank()) +
  geom_line(color=cb[3]) + facet_wrap(~ID, 
        scales = "free_y") + xlab("Year") + ylab("Correlation") 

ggsave("goa biology dfa correlations 25 year windows.png", height = 5.5, width=8, units="in")

# as for climate data, recalculate rolling correlations with all time series
modelfit <- GOA.biol$best_model

  n_ts <- dim(modelfit$data)[1]
  n_years <- dim(modelfit$data)[2]
  pred <- predicted(modelfit)
   res.df <- data.frame(ID = rep(seq_len(n_ts),
                                 n_years),
                        Time = sort(rep(seq_len(n_years), n_ts)), 
                        mean = c(t(apply(pred, c(3, 4), mean))), 
                        lo = c(t(apply(pred, c(3, 4), quantile, 0.025))),
                        hi = c(t(apply(pred, c(3, 4), quantile, 0.975))), 
                        y = c(modelfit$data)) 
  
        res.df$ID <- new.names
  
   
  res.df$year <-  rep(1972:2017, each=n_ts)   
  
  res.df$mean.res <- res.df$y - res.df$mean
  res.df$lo.res <- res.df$y - res.df$lo
  res.df$hi.res <- res.df$y - res.df$hi


modelfit <- GOA.biol$best_model

  n_ts <- dim(modelfit$data)[1]
  n_years <- dim(modelfit$data)[2]
  pred <- predicted(modelfit)
   res.df <- data.frame(ID = rep(seq_len(n_ts),
                                 n_years),
                        Time = sort(rep(seq_len(n_years), n_ts)), 
                        mean = c(t(apply(pred, c(3, 4), mean))), 
                        lo = c(t(apply(pred, c(3, 4), quantile, 0.025))),
                        hi = c(t(apply(pred, c(3, 4), quantile, 0.975))), 
                        y = c(modelfit$data)) 
  
        res.df$ID <- new.names
  
   
  res.df$year <-  rep(1972:2017, each=n_ts)   
  
  res.df$mean.res <- res.df$y - res.df$mean
  res.df$lo.res <- res.df$y - res.df$lo
  res.df$hi.res <- res.df$y - res.df$hi
  
  index <- unique(res.df$ID)

# using 25-yr rolling windows!

    dfa.cor <- data.frame()    

    for(i in 1:length(index)){    
      # i <- 1 
      temp <- res.df %>%
        filter(ID==index[i])
      
       for(ii in 13:58){
       #  ii <- 13
          win <- temp[(ii-12):(ii+12),]
          temp.cor <- data.frame(ID=unique(win$ID),
                                 year=win$year[13], 
                                 window=25,
                                 mean.cor=cor(win$y, win$mean, use="p"),
                                 n.cor=sum(!is.na(win$y)))
          dfa.cor <- rbind(dfa.cor, temp.cor)
       }  }

    # remove correlations with < 10 obs
dfa.cor <- dfa.cor %>%
  filter(n.cor>=10)
 dfa.cor$window <- as.factor(dfa.cor$window) 
 
dfa.cor <- na.omit(dfa.cor)

# and plot 25-yr windows
ggplot(filter(dfa.cor, window==25), aes(year, mean.cor)) + 
  theme_bw() + theme(axis.title.x = element_blank()) +
  geom_line(color=cb[3]) + facet_wrap(~ID, 
        scales = "free_y", ncol=4) + xlab("Year") + ylab("Correlation") 

ggsave("goa biology dfa correlations 25 year windows all time series.png", height = 6.5, width=8, units="in")
```

Test for regime probability. Use n=5 maximum states.

```{r}

y = apply(rotated$trends, c(2,3), mean)
sd_y = apply(rotated$trends, c(2,3), sd)

# run each trend sequentially through the regimes
# code to identify (1) number of changes and (2)
# where those change points occur.
set.seed(99)
f1 = find_regimes(y = y[1,], sds = sd_y[1,], max_regimes = 5)


print(f1$table) # this shows 2-regime model is best
plot_regime_model(f1$best_model)

# and combined plot

kk <- plot_regime_model(f1$best_model, plot_prob_indices=c(2))

biol.regimes <- data.frame(year=1972:2019, probability=kk$data$median, lwr=kk$data$lwr, upr=kk$data$upr)

biol.regimes$data.set <- "Biology 1972-2019"

plot.regimes <- rbind(clim.regimes, biol.regimes)

ggplot(plot.regimes, aes(year, probability, color=data.set)) +
  theme_bw() +
  geom_line()
  
```


Next step is to examine relationships between SST and the GOA biology trend.

We're interested in testing the hypothesis that the slope on sst was greater during 1972:1988 (high Aleutian Low variance) than during 1989:2013 (low Aleutian Low variance). Also interested in asking which of these periods the 2014-2016 heat wave years are most similar to.

```{r, include=F}
# first, define the function
trend_lm <- function(rotated_modelfit,
  all_years, selected_years,
  climate_dat = NULL,
  trend_number = 1, samples = 500,
  ITER = 1000, CHAINS = 1, n_eff = 50, rhat = 1.1, show_plot = TRUE) {

  total_mcmc <- dim(rotated_modelfit$trends)[1]
  draws <- sample(seq_len(total_mcmc), samples)

  yrs_i <- which(all_years %in% selected_years)
  climate_dat <- dplyr::filter(climate_dat, Year %in% selected_years)

  predictor_name = names(climate_dat)[which(names(climate_dat) != "Year")]
  formula_str = paste("dfa_trend_draw ~", predictor_name[1])
  if(length(predictor_name) > 1) {
    for(i in 2:length(predictor_name)) {formula_str = paste(formula_str, predictor_name[i], sep=" + ")}
  }
  formula <- as.formula(formula_str)

  post <- list()
  for (i in seq_along(draws)) {
    dd = climate_dat
    dd$dfa_trend_draw = rotated_modelfit$trends[draws[i], trend_number, yrs_i]
    m_temp <- stan_glm(formula, data = dd,
      iter = ITER, chains = CHAINS)
    assert_that(all(m_temp$stan_summary[,"Rhat"] < rhat))
    assert_that(all(m_temp$stan_summary[,"n_eff"] > n_eff))
    post[[i]] <- as.data.frame(as.matrix(m_temp))
  }
  post_all <- dplyr::bind_rows(post)

  if (show_plot) {
    #par(mfrow = c(1, 2))
    #plot(post_all[,predictor], type = "l", col = "#00000080", lwd = 0.5)
    #abline(v = seq(0, ITER * length(draws), ITER), col = "#FF000050")
    #plot(density(post_all[,predictor]))
    #abline(v = 0, col = "#00000050")
  }
  invisible(post_all)
}

#  load sst as the explanatory variable.

ewidata <- read.csv("updated goa climate data.csv", row.names=1)

keep <- grep("win.sst", colnames(ewidata))

clim.var <- ewidata[,keep] %>%
  mutate(year=1950:2019) %>%
  gather(key, value, -year)

win.sst <- tapply(clim.var$value, clim.var$year, mean)

years <- as.numeric(colnames(GOA.biol$best_model$data)) # these are the years for the biology model - 1972:2016

# set up climate data
cli_dat <- data.frame(Year=as.numeric(names(win.sst)),SST=win.sst)

cli_dat <- filter(cli_dat, Year %in% years) %>% mutate(SST = arm::rescale(SST))

# cli_dat$regime = as.factor(sample(c(0,1,2), size=20, replace=T))

cli_dat$slope <- 1
cli_dat$slope[cli_dat$Year %in% 1989:2013] <- 2
cli_dat$slope[cli_dat$Year %in% 2014:2019] <- 3
cli_dat$slope <- as.factor(cli_dat$slope)

# rename rotated
r <- rotated

Y = rnorm(length(cli_dat$slope))
cli_dat = as.data.frame(model.matrix(Y ~ Year + SST:slope, data=cli_dat))
# replace ':' in name for formula
names(cli_dat) = gsub(":","",names(cli_dat))
# remove named intercept
cli_dat = cli_dat[,-which(names(cli_dat)=="(Intercept)")]

set.seed(99)
mod = trend_lm(rotated_modelfit = r, all_years = 1972:2017,
  selected_years = 1972:2017, climate_dat=cli_dat)

names(mod)[2:4] <- c("1972-1988", "1989-2013", "2014-2019")
summary(mod)

# get 95% CIs

for(i in 2:4){
x <- sort(mod[,i])
print(names(mod)[i])
print(paste("median: ", median(x)))
print(paste("LCI: ", x[(0.025*25000)]))
print(paste("UCI: ", x[(0.975*25000)]))
}

# and look at the proportion of posteriors > or < 0 for each era
for(i in 2:4){
x <- mod[,i]
print(names(mod)[i])
print(paste("Proportion < 0: ", sum(x < 0)/length(x)))
print(paste("Proportion > 0: ", sum(x > 0)/length(x)))
}


melt.mod <- melt(mod, measure.vars=c("1972-1988", "1989-2013", "2014-2019"))
names(melt.mod)[3] <- "era"
melt.mod$covar <- "SST"

```

Now the PDO.

```{r, echo=F}
# 
# pdo <- read.csv("pdo.csv")
# 
# win.pdo <- pdo$NDJFM
# 
# years <- as.numeric(colnames(GOA.biol$best_model$data)) # these are the years for the biology model - 1972:2017
# 
# # set up climate data
# cli_dat <- data.frame(Year=pdo$YEAR, PDO=win.pdo)
# 
# cli_dat <- filter(cli_dat, Year %in% years) %>% mutate(PDO = arm::rescale(PDO))
# 
# # cli_dat$regime = as.factor(sample(c(0,1,2), size=20, replace=T))
# 
# cli_dat$slope <- 1
# cli_dat$slope[cli_dat$Year %in% 1989:2013] <- 2
# cli_dat$slope[cli_dat$Year %in% 2014:2017] <- 3
# cli_dat$slope <- as.factor(cli_dat$slope)
# 
# # rename rotated
# r <- rotated
# 
# Y = rnorm(length(cli_dat$slope))
# cli_dat = as.data.frame(model.matrix(Y ~ Year + PDO:slope, data=cli_dat))
# # replace ':' in name for formula
# names(cli_dat) = gsub(":","",names(cli_dat))
# # remove named intercept
# cli_dat = cli_dat[,-which(names(cli_dat)=="(Intercept)")]
# 
# set.seed(99)
# mod2 = trend_lm(rotated_modelfit = r, all_years = 1972:2017,
#   selected_years = 1972:2016, climate_dat=cli_dat)
# 
# names(mod2)[2:4] <- c("1972-1988", "1989-2013", "2014-2017")
# 
# summary(mod2)
# 
# # get 95% CIs
# 
# for(i in 2:4){
# x <- sort(mod2[,i])
# print(names(mod2)[i])
# print(paste("median: ", median(x)))
# print(paste("LCI: ", x[(0.025*25000)]))
# print(paste("UCI: ", x[(0.975*25000)]))
# }
# 
# 
# melt.mod2 <- melt(mod2, measure.vars=c("1972-1988", "1989-2013", "2014-2017"))
# names(melt.mod2)[3] <- "era"
# melt.mod2$covar <- "PDO"


```

And the NPGO. Leaving this commented out as there is no meaningfull effect of the NPGO in any era!

```{r, echo=F}

# npgo <- read.csv("winter.npgo.csv")
# 
# years <- as.numeric(colnames(GOA.biol$best_model$data)) # these are the years for the biology model - 1972:2017
# 
# # set up climate data
# cli_dat <- data.frame(Year=npgo$YEAR,NPGO=npgo$NDJFM)
# 
# cli_dat <- filter(cli_dat, Year %in% years) %>% mutate(NPGO = arm::rescale(NPGO))
# 
# # cli_dat$regime = as.factor(sample(c(0,1,2), size=20, replace=T))
# 
# cli_dat$slope <- 1
# cli_dat$slope[cli_dat$Year %in% 1989:2013] <- 2
# cli_dat$slope[cli_dat$Year %in% 2014:2017] <- 3
# cli_dat$slope <- as.factor(cli_dat$slope)
# 
# # rename rotated
# r <- rotated
# 
# Y = rnorm(length(cli_dat$slope))
# cli_dat = as.data.frame(model.matrix(Y ~ Year + NPGO:slope, data=cli_dat))
# # replace ':' in name for formula
# names(cli_dat) = gsub(":","",names(cli_dat))
# # remove named intercept
# cli_dat = cli_dat[,-which(names(cli_dat)=="(Intercept)")]
# 
# mod3 = trend_lm(rotated_modelfit = r, all_years = 1972:2017,
#   selected_years = 1972:2017, climate_dat=cli_dat)
# 
# 
# summary(mod3)
# 
# names(mod3)[2:4] <- c("1972-1988", "1989-2013", "2014-2017")
# 
# melt.mod3 <- melt(mod3, measure.vars=c("1972-1988", "1989-2013", "2014-2017"))
# names(melt.mod3)[3] <- "era"
# melt.mod3$covar <- "NPGO"
# 
# pdf("Fig. 3C goa.biol.on.npgo.pdf", 6, 4)
# ggplot(melt.mod3, aes(x=value, color=era)) + geom_density() + geom_hline(yintercept=0) + geom_vline(xintercept = 0, lty=2) + labs(title="C) NPGO")
# dev.off()

```

Combine and plot
```{r}
plot.melt <- rbind(melt.mod, melt.mod2)
plot.melt$covar <- reorder(plot.melt$covar, desc(plot.melt$covar))
plot.melt$era <- reorder(plot.melt$era, desc(plot.melt$era))
ggplot(plot.melt, aes(x=era, y=value)) +
  theme_bw() + 
  geom_violin(fill=cb[3]) +
  geom_hline(yintercept=0, lty=2) +
  geom_vline(xintercept = 0, lty=2) +
  facet_wrap(~covar) +
  theme(axis.title.y = element_blank()) +
  ylab("Slope") +
  coord_flip()

ggsave("goa biology era sst pdo slopes.png", width=6, height=4, units="in")

# make a SST-only plot
ggplot(melt.mod, aes(x=value, fill=era)) +
  theme_bw() + 
  geom_density(alpha=0.6) +
  geom_vline(xintercept = 0, lty=2) +
  scale_fill_manual(values = cb[c(4, 6, 2)]) +
  theme(legend.title = element_blank(), legend.position = c(0.8, 0.8)) +
  xlab("Slope") + ylab("Density") +
  xlim(-5,12)

ggsave("goa biology era sst slopes.png", width=5, height=4, units="in")

```

## GOA ichthyo results.

One trend model was again the best.

```{r, echo=F}
# GOA.ich <- readRDS("/Users/MikeLitzow/Documents/R/Fate/fate-ewi/GOA_ich_7.19.18.one.trend.rds") 
GOA.ich <- readRDS("all_plankton_12.11.19.one.trend.rds") 
GOA.ich$summary
```

### Fig. _A

```{r, echo=F}

# reload the version of data used
# load updated ewidata!
# load updated ewidata!
# ewidata <- as.tibble(read.csv("ewidata.csv", row.names=1))
# 
# # limit to GOA
# GOA <- ewidata[ewidata$system %in% c("WGOA", "EGOA"),]
# unique(GOA$code)
# 
# # limit to ichthy
# 
# keep <- grep("ICH", GOA$code)
# 
# GOA <- GOA[keep,]

# recover the years and names for plots!
# using GOA from 'updated plankton model.R'
sub_data = GOA

melted = melt(sub_data[, c("code", "year", "value")], id.vars = c("code", "year"))
Y <- dcast(melted, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])

rotated = rotate_trends(GOA.ich$best_model) 
# new.names <- c("sandlance", "ronquils", "walleye.pollock", "Pacific.cod", "flathead.sole", "n.rock.sole", "rockfish")
# 
#  check <- data.frame(names=names, newnames=new.names)
#  check

 # back to the bespoke code!
loadings.1 <- as.data.frame(rotated$Z_rot[,,1])
names(loadings.1)  <- new.names

# drop columns that don't meet threshold
# first, figure out the proportion above/below 0
f <- function(x) max(sum(x<0)/length(x), sum(x>0)/length(x))
  
prop1 <- apply(loadings.1, 2, f)
prop1
keep <- prop1 > 0.95

loadings.1 <- loadings.1[,keep]

# plot
plot.load <- loadings.1 %>%
  gather()

rank <- tapply(plot.load$value, plot.load$key, mean)
plot.load$rank <- rank[match(plot.load$key, names(rank))]
  
plot.load$key <- reorder(plot.load$key, plot.load$rank)

# set pallette
cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

plot.a <- ggplot(plot.load, aes(key, value)) +
  theme_bw() +
  geom_violin(fill=cb[3]) +
  geom_hline(yintercept = 0) +
  theme(axis.title.y = element_blank()) + ylab("Loading") +
  coord_flip() +
  ggtitle("a) Ichthyoplankton loadings") +
  theme(title = element_text(size=8)) 
  

plot.a

```


```{r, echo=F}
# trends
plot.trend <- data.frame(year=as.numeric(as.character(colnames(Y))), trend=as.vector(rotated$trends_mean),
                         lo=as.vector(rotated$trends_lower),
                         hi=as.vector(rotated$trends_upper))

plot.b <- ggplot(plot.trend, aes(year, trend)) +
  theme_bw() +
  geom_line(color=cb[3]) +
  geom_ribbon(aes(ymin=lo, ymax=hi), fill=cb[3], alpha=0.4) +
  geom_hline(yintercept = 0) + ylab("Trend value") +
  xlab("Year") +
  ggtitle("b) Ichthyoplankton trend") +
  theme(title = element_text(size=8))

plot.b
# png("combined GOA climate loading and trend plot.png", 8, 4, units = "in", res=300)
# 
# ggpubr::ggarrange(plot.a, plot.b, ncol=2)
# 
# dev.off()
```


Test for regime probability. Use n=5 maximum states.

```{r, include=F}

y = apply(rotated$trends, c(2,3), mean)
sd_y = apply(rotated$trends, c(2,3), sd)

# run each trend sequentially through the regimes
# code to identify (1) number of changes and (2)
# where those change points occur.
set.seed(11)
f1 = find_regimes(y = y[1,], sds = sd_y[1,], max_regimes = 5)


print(f1$table) # this shows 2-regime model is best
plot_regime_model(f1$best_model)

# and combined plot

kk <- plot_regime_model(f1$best_model, plot_prob_indices=c(1))

ichthyo.regimes <- data.frame(year=plot.trend$year, probability=kk$data$median, lwr=kk$data$lwr, upr=kk$data$upr)

ichthyo.regimes$data.set <- "Plankton 1981-2019"

plot.regimes <- rbind(clim.regimes, biol.regimes, ichthyo.regimes)
plot.regimes$jitter <- ifelse(plot.regimes$data.set=="Biology 1972-2019" & plot.regimes$probability>0.99, 1.004, plot.regimes$probability)

plot.regimes$order <- ifelse(plot.regimes$data.set=="Plankton 1981-2019", 1,
                             ifelse(plot.regimes$data.set=="Biology 1972-2019", 2, 3))

plot.regimes$data.set <- reorder(plot.regimes$data.set, plot.regimes$order)

ggplot(plot.regimes, aes(year, jitter, color=data.set, fill=data.set)) +
  theme_bw() +
  geom_line() +
  geom_ribbon(aes(ymin=lwr, ymax=upr), alpha=0.2, color=NA) +
  scale_color_manual(values=cb[c(2,7,6)], guide=guide_legend(reverse=T)) + scale_fill_manual(values=cb[c(2,7,6)], guide=guide_legend(reverse=T)) +
  xlab("Year") + ylab("Probability") +
  theme(legend.title = element_blank(), legend.position = 'top') 

ggsave("updated HMM regime plot.png", width = 6, height = 4, units='in')
```

Next step is to examine relationships between SST and the ichthyo trend.

We're interested in testing the hypothesis that the slope on sst was greater during 1972:1988 (high Aleutian Low variance) than during 1989:2013 (low Aleutian Low variance). Also interested in asking which of these periods the 2014-106 heat wave years are most similar to.

```{r, include=F}
#  load sst as the explanatory variable.

ewidata <- read.csv("updated goa climate data.csv", row.names=1)

keep <- grep("win.sst", colnames(ewidata))

clim.var <- ewidata[,keep] %>%
  mutate(year=1950:2019) %>%
  gather(key, value, -year)

win.sst <- tapply(clim.var$value, clim.var$year, mean)

years <- as.numeric(colnames(GOA.ich$best_model$data)) 

# set up climate data
cli_dat <- data.frame(Year=as.numeric(names(win.sst)),SST=win.sst)

cli_dat <- filter(cli_dat, Year %in% years) %>% mutate(SST = arm::rescale(SST))

# cli_dat$regime = as.factor(sample(c(0,1,2), size=20, replace=T))

# this time series is too short to divide up into eras!
cli_dat$slope <- 1
#cli_dat$slope[cli_dat$Year %in% 1997:2013] <- 2
#cli_dat$slope[cli_dat$Year %in% 2014:2016] <- 3
cli_dat$slope <- as.factor(cli_dat$slope)

# rename rotated
r <- rotated

Y = rnorm(length(cli_dat$slope))
cli_dat = as.data.frame(model.matrix(Y ~ Year + SST, data=cli_dat))
# replace ':' in name for formula
names(cli_dat) = gsub(":","",names(cli_dat))
# remove named intercept
cli_dat = cli_dat[,-which(names(cli_dat)=="(Intercept)")]

set.seed(99)
mod = trend_lm(rotated_modelfit = r, all_years = years,
  selected_years = years, climate_dat=cli_dat)

summary(mod)

# get 95% CIs
x <- sort(mod[,2])
print(names(mod)[2])
print(paste("median: ", median(x)))
print(paste("LCI: ", x[(0.025*25000)]))
print(paste("UCI: ", x[(0.975*25000)]))

# dropping this b/c we have no eras for this short TS!
# melt.mod <- melt(mod, measure.vars=c("1972-1988", "1989-2013", "2014-2016"))
# names(melt.mod)[3] <- "era"

plot.c <- ggplot(mod, aes(x=SST)) +
  theme_bw() +
  geom_density(fill=cb[3]) + 
  geom_hline(yintercept=0) + 
  geom_vline(xintercept = 0, lty=2) + 
  xlab("Slope") + 
  ylab("Density") +
  ggtitle(("c) Ichthyo. slope on SST")) +
  theme(title=element_text(size=8))



```

Now the zoops model.
These are now fit as three models- one for Seward Line, one for Icy Strait, one for large-scale (CPR & PP)
```{r, echo=F}
seward <- readRDS("Sewardline_11.19.19.one.trend.rds") 
seward$summary
```

```{r, echo=F}

# load updated ewidata!
ewidata <- as.tibble(read.csv("ewidata.plankton.updated.csv"))

keep <- grep("SEWARD", ewidata$code)
seward.dat <- ewidata[keep,]
unique(seward.dat$code)


# recover the years and names for plots!
sub_data = seward.dat

melted = melt(sub_data[, c("code", "year", "value")], id.vars = c("code", "year"))
Y <- dcast(melted, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])

rotated = rotate_trends(seward$best_model) 

new.names <- c("Calanoid.size.Sept", "Calanoid.size.May", "Euphausid.size.Sept", "Euphausid.size.May",
               "Calanoid.biomass.Sept", "Calanoid.biomass.May", "Euphausid.biomass.Sept", "Euphausid.biomass.May")

# back to the bespoke code!
loadings.1 <- as.data.frame(rotated$Z_rot[,,1])
names(loadings.1)  <- new.names

# drop columns that don't meet threshold
# first, figure out the proportion above/below 0
f <- function(x) max(sum(x<0)/length(x), sum(x>0)/length(x))
  
prop1 <- apply(loadings.1, 2, f)
prop1
keep <- prop1 > 0.95

loadings.1 <- loadings.1[,keep]

# plot
plot.load <- loadings.1 %>%
  gather()

rank <- tapply(plot.load$value, plot.load$key, mean)
plot.load$rank <- rank[match(plot.load$key, names(rank))]
  
plot.load$key <- reorder(plot.load$key, plot.load$rank)

# set pallette
cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

plot.d <- ggplot(plot.load, aes(key, value)) +
  theme_bw() +
  geom_violin(fill=cb[3]) +
  geom_hline(yintercept = 0) +
  theme(axis.title.y = element_blank()) + ylab("Loading") +
  coord_flip() +
  ggtitle("d) Sewardline loadings") +
  theme(title = element_text(size=8))

plot.d
```


```{r, echo=F}
# trends
plot.trend <- data.frame(year=as.numeric(as.character(colnames(Y))), trend=as.vector(rotated$trends_mean),
                         lo=as.vector(rotated$trends_lower),
                         hi=as.vector(rotated$trends_upper))

plot.e <- ggplot(plot.trend, aes(year, trend)) +
  theme_bw() +
  geom_line(color=cb[3]) +
  geom_ribbon(aes(ymin=lo, ymax=hi), fill=cb[3], alpha=0.4) +
  geom_hline(yintercept = 0) + ylab("Trend value") + xlab("Year") +
  ggtitle("e) Sewardline trend") +
  theme(title = element_text(size=8))

plot.e
```


Test for regime probability. Use n=3 maximum states.

```{r, include=F}

y = apply(rotated$trends, c(2,3), mean)
sd_y = apply(rotated$trends, c(2,3), sd)

# run each trend sequentially through the regimes
# code to identify (1) number of changes and (2)
# where those change points occur.
set.seed(11)
f1 = find_regimes(y = y[1,], sds = sd_y[1,], max_regimes = 3)


print(f1$table) # this shows 2-regime model is best
plot_regime_model(f1$best_model)

# and combined plot

kk <- plot_regime_model(f1$best_model, plot_prob_indices=c(1))

seward.regimes <- data.frame(year=plot.trend$year, probability=kk$data$median)

seward.regimes$data.set <- "Sewardline 1998-2018"

plot.regimes <- rbind(clim.regimes, biol.regimes, ichthyo.regimes, zoop.regimes)

plot.regimes$plot.order <- ifelse(plot.regimes$data.set=="Climate 1950-2019", 1, 
                                  ifelse(plot.regimes$data.set=="Biology 1972-2017", 2,
                                  ifelse(plot.regimes$data.set=="Ichthyoplankton 1980-2015", 3,
                                  4)))
plot.regimes$data.set <- reorder(plot.regimes$data.set, plot.regimes$plot.order)

ggplot(plot.regimes, aes(year, probability, color=data.set)) +
  theme_bw() +
  geom_line() +
  theme(axis.title.x = element_blank(), legend.title = element_blank(), legend.position = 'top') + 
  scale_color_manual(values = cb[c(6,4,2,7,8)], guide=guide_legend(nrow=2)) 
  
ggsave("regime probabilities combined.png", width = 5, height = 3.5, units = "in")

```


Next step is to examine relationships between SST and the zoop trend.

We're interested in testing the hypothesis that the slope on sst was greater during 1972:1988 (high Aleutian Low variance) than during 1989:2013 (low Aleutian Low variance). Also interested in asking which of these periods the 2014-106 heat wave years are most similar to.

```{r, include=F}
#  load sst as the explanatory variable.
ewidata <- read.csv("updated goa climate data.csv", row.names=1)

keep <- grep("win.sst", colnames(ewidata))

clim.var <- ewidata[,keep] %>%
  mutate(year=1950:2019) %>%
  gather(key, value, -year)

win.sst <- tapply(clim.var$value, clim.var$year, mean)

years <- as.numeric(colnames(seward$best_model$data)) 

# set up climate data
cli_dat <- data.frame(Year=as.numeric(names(win.sst)),SST=win.sst)

cli_dat <- filter(cli_dat, Year %in% years) %>% mutate(SST = arm::rescale(SST))

# cli_dat$regime = as.factor(sample(c(0,1,2), size=20, replace=T))

cli_dat$slope <- 1
#cli_dat$slope[cli_dat$Year %in% 1997:2013] <- 2
#cli_dat$slope[cli_dat$Year %in% 2014:2016] <- 3
cli_dat$slope <- as.factor(cli_dat$slope)

# rename rotated
r <- rotated

Y = rnorm(length(cli_dat$slope))
cli_dat = as.data.frame(model.matrix(Y ~ Year + SST, data=cli_dat))
# replace ':' in name for formula
names(cli_dat) = gsub(":","",names(cli_dat))
# remove named intercept
cli_dat = cli_dat[,-which(names(cli_dat)=="(Intercept)")]

set.seed(99)
mod = trend_lm(rotated_modelfit = r, all_years = years,
  selected_years = years, climate_dat=cli_dat)

summary(mod)

# get 95% CIs
x <- sort(mod[,2])
print(names(mod)[2])
print(paste("median: ", median(x)))
print(paste("LCI: ", x[(0.025*25000)]))
print(paste("UCI: ", x[(0.975*25000)]))

plot.f <- ggplot(mod, aes(x=SST)) +
  theme_bw() +
  geom_density(fill=cb[3]) + 
  geom_hline(yintercept=0) + 
  geom_vline(xintercept = 0, lty=2) + 
  xlab("Slope") + 
  ylab("Density") +
  ggtitle(("f) Sewardline slope on SST")) +
  theme(title = element_text(size=8))

```

Now the icy strait model.

```{r, echo=F}
icy <- readRDS("ICY_11.20.19.one.trend.rds") 
icy$summary
```

```{r, echo=F}

# load updated ewidata!
ewidata <- as.tibble(read.csv("ewidata.plankton.updated.csv"))

keep <- grep("ICY", ewidata$code)
icy.dat <- ewidata[keep,]
unique(icy.dat$code)

# drop total density
drop <- grep("TOTDEN", icy.dat$code)
icy.dat <- icy.dat[-drop,]

# recover the years and names for plots!
sub_data = icy.dat

melted = melt(sub_data[, c("code", "year", "value")], id.vars = c("code", "year"))
Y <- dcast(melted, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])

rotated = rotate_trends(icy$best_model) 

new.names <- c("Amphiphod", "Large.copepod", "Small.copepod", "Euphausid",
               "Gastropod")

# back to the bespoke code!
loadings.1 <- as.data.frame(rotated$Z_rot[,,1])
names(loadings.1)  <- new.names

# drop columns that don't meet threshold
# first, figure out the proportion above/below 0
f <- function(x) max(sum(x<0)/length(x), sum(x>0)/length(x))
  
prop1 <- apply(loadings.1, 2, f)
prop1
keep <- prop1 > 0.95

loadings.1 <- loadings.1[,keep]

# plot
# AND THERE IS ONLY ONE TS WITH > 0.95 LOADINGS!
plot.load <- loadings.1 %>%
  gather()

rank <- tapply(plot.load$value, plot.load$key, mean)
plot.load$rank <- rank[match(plot.load$key, names(rank))]
  
plot.load$key <- reorder(plot.load$key, plot.load$rank)

# set pallette
cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

plot.d <- ggplot(plot.load, aes(key, value)) +
  theme_bw() +
  geom_violin(fill=cb[3]) +
  geom_hline(yintercept = 0) +
  theme(axis.title.y = element_blank()) + ylab("Loading") +
  coord_flip() +
  ggtitle("d) Sewardline loadings") +
  theme(title = element_text(size=8))

plot.d
```

Now the large-scale!

```{r, echo=F}
large <- readRDS("PP_CPR_11.20.19.one.trend.rds") 
large$summary
```

```{r, echo=F}

# load updated ewidata!
ewidata <- as.tibble(read.csv("ewidata.plankton.updated.csv"))

keep <- c(grep("PP", ewidata$code), grep("CPR", ewidata$code))
large.dat <- ewidata[keep,]
unique(large.dat$code)


# recover the years and names for plots!
sub_data = large.dat

melted = melt(sub_data[, c("code", "year", "value")], id.vars = c("code", "year"))
Y <- dcast(melted, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])

rotated = rotate_trends(large$best_model) 

new.names <- c("Copepod.size", "Diatom.abundance", "Large.copepod.abundance", "Mesozoop.abundance",
               "Small.copepod.abundance", "Bloom.amplitude", "Bloom.duration", "Bloom.start")

# back to the bespoke code!
loadings.1 <- as.data.frame(rotated$Z_rot[,,1])
names(loadings.1)  <- new.names

# drop columns that don't meet threshold
# first, figure out the proportion above/below 0
f <- function(x) max(sum(x<0)/length(x), sum(x>0)/length(x))
  
prop1 <- apply(loadings.1, 2, f)
prop1
keep <- prop1 > 0.95

loadings.1 <- loadings.1[,keep]

# plot
plot.load <- loadings.1 %>%
  gather()

rank <- tapply(plot.load$value, plot.load$key, mean)
plot.load$rank <- rank[match(plot.load$key, names(rank))]
  
plot.load$key <- reorder(plot.load$key, plot.load$rank)

# set pallette
cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

plot.g <- ggplot(plot.load, aes(key, value)) +
  theme_bw() +
  geom_violin(fill=cb[3]) +
  geom_hline(yintercept = 0) +
  theme(axis.title.y = element_blank()) + ylab("Loading") +
  coord_flip() +
  ggtitle("g) Large-scale loadings") +
  theme(title = element_text(size=8))

plot.g
```

```{r, echo=F}
# trends
plot.trend <- data.frame(year=as.numeric(as.character(colnames(Y))), trend=as.vector(rotated$trends_mean),
                         lo=as.vector(rotated$trends_lower),
                         hi=as.vector(rotated$trends_upper))

plot.h <- ggplot(plot.trend, aes(year, trend)) +
  theme_bw() +
  geom_line(color=cb[3]) +
  geom_ribbon(aes(ymin=lo, ymax=hi), fill=cb[3], alpha=0.4) +
  geom_hline(yintercept = 0) + ylab("Trend value") + xlab("Year") +
  ggtitle("h) Large-scale trend") +
  theme(title = element_text(size=8))

plot.h
```

Now test for SST effect.
```{r, include=F}
#  load sst as the explanatory variable.
ewidata <- read.csv("updated goa climate data.csv", row.names=1)

keep <- grep("win.sst", colnames(ewidata))

clim.var <- ewidata[,keep] %>%
  mutate(year=1950:2019) %>%
  gather(key, value, -year)

win.sst <- tapply(clim.var$value, clim.var$year, mean)

years <- as.numeric(colnames(seward$best_model$data)) 

# set up climate data
cli_dat <- data.frame(Year=as.numeric(names(win.sst)),SST=win.sst)

cli_dat <- filter(cli_dat, Year %in% years) %>% mutate(SST = arm::rescale(SST))

# cli_dat$regime = as.factor(sample(c(0,1,2), size=20, replace=T))

cli_dat$slope <- 1
#cli_dat$slope[cli_dat$Year %in% 1997:2013] <- 2
#cli_dat$slope[cli_dat$Year %in% 2014:2016] <- 3
cli_dat$slope <- as.factor(cli_dat$slope)

# rename rotated
r <- rotated

Y = rnorm(length(cli_dat$slope))
cli_dat = as.data.frame(model.matrix(Y ~ Year + SST, data=cli_dat))
# replace ':' in name for formula
names(cli_dat) = gsub(":","",names(cli_dat))
# remove named intercept
cli_dat = cli_dat[,-which(names(cli_dat)=="(Intercept)")]

set.seed(99)
mod = trend_lm(rotated_modelfit = r, all_years = years,
  selected_years = years, climate_dat=cli_dat)

summary(mod)

# get 95% CIs
x <- sort(mod[,2])
print(names(mod)[2])
print(paste("median: ", median(x)))
print(paste("LCI: ", x[(0.025*25000)]))
print(paste("UCI: ", x[(0.975*25000)]))

plot.i <- ggplot(mod, aes(x=SST)) +
  theme_bw() +
  geom_density(fill=cb[3]) + 
  geom_hline(yintercept=0) + 
  geom_vline(xintercept = 0, lty=2) + 
  xlab("Slope") + 
  ylab("Density") +
  ggtitle(("i) Large-scale slope on SST")) +
  theme(title = element_text(size=8))

```

Look at era-specific effects.
```{r, include=F}
# first, define the function
# increasing to 4000 iterations!
trend_lm <- function(rotated_modelfit,
  all_years, selected_years,
  climate_dat = NULL,
  trend_number = 1, samples = 50,
  ITER = 4000, CHAINS = 1, n_eff = 50, rhat = 1.1, show_plot = TRUE) { # increasing from 1000 to 4000 iterations to help plankton model converge

  total_mcmc <- dim(rotated_modelfit$trends)[1]
  draws <- sample(seq_len(total_mcmc), samples)

  yrs_i <- which(all_years %in% selected_years)
  climate_dat <- dplyr::filter(climate_dat, Year %in% selected_years)

  predictor_name = names(climate_dat)[which(names(climate_dat) != "Year")]
  formula_str = paste("dfa_trend_draw ~", predictor_name[1])
  if(length(predictor_name) > 1) {
    for(i in 2:length(predictor_name)) {formula_str = paste(formula_str, predictor_name[i], sep=" + ")}
  }
  formula <- as.formula(formula_str)

  post <- list()
  for (i in seq_along(draws)) {
    dd = climate_dat
    dd$dfa_trend_draw = rotated_modelfit$trends[draws[i], trend_number, yrs_i]
    m_temp <- stan_glm(formula, data = dd,
      iter = ITER, chains = CHAINS)
    assert_that(all(m_temp$stan_summary[,"Rhat"] < rhat))
    assert_that(all(m_temp$stan_summary[,"n_eff"] > n_eff))
    post[[i]] <- as.data.frame(as.matrix(m_temp))
  }
  post_all <- dplyr::bind_rows(post)

  if (show_plot) {
    #par(mfrow = c(1, 2))
    #plot(post_all[,predictor], type = "l", col = "#00000080", lwd = 0.5)
    #abline(v = seq(0, ITER * length(draws), ITER), col = "#FF000050")
    #plot(density(post_all[,predictor]))
    #abline(v = 0, col = "#00000050")
  }
  invisible(post_all)
}

#  load sst as the explanatory variable.

ewidata <- read.csv("updated goa climate data.csv", row.names=1)

keep <- grep("win.sst", colnames(ewidata))

clim.var <- ewidata[,keep] %>%
  mutate(year=1950:2019) %>%
  gather(key, value, -year)

win.sst <- tapply(clim.var$value, clim.var$year, mean)

years <- as.numeric(colnames(large$best_model$data)) # these are the years for the biology model - 1972:2016

# set up climate data
cli_dat <- data.frame(Year=as.numeric(names(win.sst)),SST=win.sst)

cli_dat <- filter(cli_dat, Year %in% years) %>% mutate(SST = arm::rescale(SST))

# cli_dat$regime = as.factor(sample(c(0,1,2), size=20, replace=T))

cli_dat$slope <- 1
cli_dat$slope[cli_dat$Year %in% 2014:2019] <- 2
cli_dat$slope <- as.factor(cli_dat$slope)

# rename rotated
r <- rotated

Y = rnorm(length(cli_dat$slope))
cli_dat = as.data.frame(model.matrix(Y ~ Year + SST:slope, data=cli_dat))
# replace ':' in name for formula
names(cli_dat) = gsub(":","",names(cli_dat))
# remove named intercept
cli_dat = cli_dat[,-which(names(cli_dat)=="(Intercept)")]

set.seed(99)
mod = trend_lm(rotated_modelfit = r, all_years = 1998:2019,
  selected_years = 1998:2019, climate_dat=cli_dat)

names(mod)[2:3] <- c("1998-2013", "2014-2019")
summary(mod)

# get 95% CIs

for(i in 2:3){
x <- sort(mod[,i])
print(names(mod)[i])
print(paste("median: ", median(x)))
print(paste("LCI: ", x[(0.025*25000)]))
print(paste("UCI: ", x[(0.975*25000)]))
}

melt.mod <- melt(mod, measure.vars=c("1998-2013", "2014-2019"))
names(melt.mod)[3] <- "era"
melt.mod$covar <- "SST"


# make a SST-only plot
ggplot(melt.mod, aes(x=value, fill=era)) +
  theme_bw() + 
  geom_density(alpha=0.6) +
  geom_vline(xintercept = 0, lty=2) +
  scale_fill_manual(values = cb[c(6, 2)]) +
  theme(legend.title = element_blank(), legend.position = c(0.8, 0.8)) +
  xlab("Slope") #+
  #xlim(-5,12)

ggsave("large area era sst slopes.png", width=5, height=4, units="in")

```

And combine into a single plot.

```{r}
png("combined updated plankton time series plots.png", 8,7.5, units="in", res=300)

ggpubr::ggarrange(plot.a, plot.b, plot.c, plot.d, plot.e, plot.f, plot.g, plot.h, plot.i,
          ncol=3, widths=c(1, 1, 0.8), nrow=3)

dev.off()
```

Or, much better! I ran a single model for the entire plankton TS and this appears to work...

```{r, echo=F}
all <- readRDS("all_plankton_12.11.19.one.trend.rds")
# all <- readRDS("GOA_plankton_11.18.19.one.trends.rds") 
all$summary
```

```{r, echo=F}

# load updated ewidata!
ewidata <- as.tibble(read.csv("ewidata.plankton.updated.csv"))

GOA <- ewidata

# drop total icy zoops!
drop <- grep("ICY.ZOOP.TOTDEN", GOA$code)
GOA <- GOA[-drop,]

# select ICY, PP, Seward, CPR, and ichthyo!
keep <- c(grep("ICY", GOA$code), grep("PP_", GOA$code), grep("CPR", GOA$code), grep("SEWAR", GOA$code), grep("ICH", GOA$code))
GOA <- GOA[keep,]

# recover the years and names for plots!
sub_data = GOA

melted = melt(sub_data[, c("code", "year", "value")], id.vars = c("code", "year"))
Y <- dcast(melted, code ~ year)
names = Y$code
Y = as.matrix(Y[,-which(names(Y) == "code")])

rotated = rotate_trends(all$best_model) 

new.names <- c("CPR copepod size", "CPR diatom", "CPR large copepod", "CPR mesozooplankton", "CPR small copepod", "Ichthyo. - sand lance", 
               "Ichthyo. - ronquils", "Ichthyo. - pollock", "Ichthyo. - Pacific cod", "Ichthyo. - flathead sole", "Ichthyo. - rock sole", "Ichthyo. - rockfishes", "Icy Strait amphipod",
               "Icy Strait large copepod", "Icy Strait small copepod", "Icy Strait euphausid", "Icy Strait gastropod", "Bloom amplitude", "Bloom duration", "Bloom start", "Seward calanoid size Sept.",
               "Seward calanoid size May", "Seward euphausid size Sept.", "Seward euphausid size May", "Seward calanoid Sept.", "Seward calanoid May", "Seward euphausid Sept.", "Seward euphausid May")

# and check
check <- data.frame(names, new.names)
check

# back to the bespoke code!
loadings.1 <- as.data.frame(rotated$Z_rot[,,1])
names(loadings.1)  <- new.names

# drop columns that don't meet threshold
# first, figure out the proportion above/below 0
f <- function(x) max(sum(x<0)/length(x), sum(x>0)/length(x))
  
prop1 <- apply(loadings.1, 2, f)
prop1

# export to share with collaborators
q.025 <- function(x) {return(quantile(x, probs=0.025))}
q.975 <- function(x) {return(quantile(x, probs=0.975))}
export <- data.frame(name=names(loadings.1), mean=colMeans(loadings.1), LCI=apply(loadings.1, 2, q.025), UCI=apply(loadings.1, 2, q.975))
export[,2:4] <- round(export[,2:4],3)
export <- export %>%
  arrange(mean)

write.csv(export, "plankton loadings.csv", row.names = F)


keep <- prop1 > 0.90 # changing to 0.9!

loadings.1 <- loadings.1[,keep]

# plot

plot.load <- loadings.1 %>%
  gather()

rank <- tapply(plot.load$value, plot.load$key, mean)
plot.load$rank <- rank[match(plot.load$key, names(rank))]
  
plot.load$key <- reorder(plot.load$key, plot.load$rank)

# set pallette
cb <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

plot.a <- ggplot(plot.load, aes(key, value)) +
  theme_bw() +
  geom_violin(fill=cb[3], color=NA) +
  geom_hline(yintercept = 0) +
  theme(axis.title.y = element_blank()) + ylab("Loading") +
  coord_flip() +
  ggtitle("a) Plankton loadings") +
  theme(title = element_text(size=8)) +
  ylim(-2,2)

plot.a
```

And trend.

```{r, echo=F}
# trends
plot.trend <- data.frame(year=as.numeric(as.character(colnames(Y))), trend=as.vector(rotated$trends_mean),
                         lo=as.vector(rotated$trends_lower),
                         hi=as.vector(rotated$trends_upper))

plot.b <- ggplot(plot.trend, aes(year, trend)) +
  theme_bw() +
  geom_line(color=cb[3]) +
  geom_ribbon(aes(ymin=lo, ymax=hi), fill=cb[3], alpha=0.4) +
  geom_hline(yintercept = 0) + ylab("Trend value") + xlab("Year") +
  ggtitle("b) Plankton trend") +
  theme(title = element_text(size=8))

plot.b
```

Now the slope on SST.

```{r, include=F}
#  load sst as the explanatory variable.
ewidata <- read.csv("updated goa climate data.csv", row.names=1)

keep <- grep("win.sst", colnames(ewidata))

clim.var <- ewidata[,keep] %>%
  mutate(year=1950:2019) %>%
  gather(key, value, -year)

win.sst <- tapply(clim.var$value, clim.var$year, mean)

years <- as.numeric(colnames(all$best_model$data)) 

# set up climate data
cli_dat <- data.frame(Year=as.numeric(names(win.sst)),SST=win.sst)

cli_dat <- filter(cli_dat, Year %in% years) %>% mutate(SST = arm::rescale(SST))

# cli_dat$regime = as.factor(sample(c(0,1,2), size=20, replace=T))

cli_dat$slope <- 1
#cli_dat$slope[cli_dat$Year %in% 1997:2013] <- 2
#cli_dat$slope[cli_dat$Year %in% 2014:2016] <- 3
cli_dat$slope <- as.factor(cli_dat$slope)

# rename rotated
r <- rotated

Y = rnorm(length(cli_dat$slope))
cli_dat = as.data.frame(model.matrix(Y ~ Year + SST, data=cli_dat))
# replace ':' in name for formula
names(cli_dat) = gsub(":","",names(cli_dat))
# remove named intercept
cli_dat = cli_dat[,-which(names(cli_dat)=="(Intercept)")]

set.seed(99)
mod = trend_lm(rotated_modelfit = r, all_years = years,
  selected_years = years, climate_dat=cli_dat)

summary(mod)

# get 95% CIs
x <- sort(mod[,2])
print(names(mod)[2])
print(paste("median: ", median(x)))
print(paste("LCI: ", x[(0.025*25000)]))
print(paste("UCI: ", x[(0.975*25000)]))

# and look at the proportion of posteriors > or < 0 

x <- mod[,2]
print(names(mod)[i])
print(paste("Proportion < 0: ", sum(x < 0)/length(x)))
print(paste("Proportion > 0: ", sum(x > 0)/length(x)))


plot.c <- ggplot(mod, aes(x=SST)) +
  theme_bw() +
  geom_density(fill=cb[3], color=NA) + 
  geom_hline(yintercept=0) + 
  geom_vline(xintercept = 0, lty=2) + 
  xlab("Slope") + 
  ylab("Density") +
  ggtitle(("c) Plankton slope on SST")) +
  theme(title = element_text(size=8)) +
  xlim(-3.2,0.5)

plot.c
```

And combine into a single plot.

```{r}
png("combined all plankton time series plots.png", 10, 4, units="in", res=300)

ggpubr::ggarrange(plot.a, plot.b, plot.c,
          ncol=3, widths=c(1, 1.3, 0.8), nrow=1)


dev.off()
#######

plot.null <- ggplot() + theme_void()

png("combined all plankton time series plots.png", 6, 6, units="in", res=300)

ggpubr::ggarrange(ggpubr::ggarrange(plot.null,plot.a, plot.null, ncol=3, nrow=1, widths=c(0.1, 1, 0.2)),
                  ggpubr::ggarrange(plot.b, plot.c, ncol=2, widths=c(1.5, 0.8), nrow=1),
                  nrow=2, heights=c(1, 0.8))


dev.off()

```

Bimodal - evidence of nonstationary slope?

```{r}

#  load sst as the explanatory variable.

ewidata <- read.csv("updated goa climate data.csv", row.names=1)

keep <- grep("win.sst", colnames(ewidata))

clim.var <- ewidata[,keep] %>%
  mutate(year=1950:2019) %>%
  gather(key, value, -year)

win.sst <- tapply(clim.var$value, clim.var$year, mean)

years <- as.numeric(colnames(all$best_model$data)) # these are the years for the biology model - 1972:2016

# set up climate data
cli_dat <- data.frame(Year=as.numeric(names(win.sst)),SST=win.sst)

cli_dat <- filter(cli_dat, Year %in% years) %>% mutate(SST = arm::rescale(SST))

# cli_dat$regime = as.factor(sample(c(0,1,2), size=20, replace=T))

cli_dat$slope <- 1
cli_dat$slope[cli_dat$Year %in% 1989:2013] <- 2
cli_dat$slope[cli_dat$Year %in% 2014:2019] <- 3
cli_dat$slope <- as.factor(cli_dat$slope)

# rename rotated
r <- rotated

Y = rnorm(length(cli_dat$slope))
cli_dat = as.data.frame(model.matrix(Y ~ Year + SST:slope, data=cli_dat))
# replace ':' in name for formula
names(cli_dat) = gsub(":","",names(cli_dat))
# remove named intercept
cli_dat = cli_dat[,-which(names(cli_dat)=="(Intercept)")]

set.seed(99)
mod = trend_lm(rotated_modelfit = r, all_years = years[years %in% 1981:2019],
  selected_years = years[years %in% 1981:2019], climate_dat=cli_dat)

names(mod)[2:4] <- c("1981-1988", "1989-2013", "2014-2017")
summary(mod)

# get 95% CIs

for(i in 2:4){
x <- sort(mod[,i])
print(names(mod)[i])
print(paste("median: ", median(x)))
print(paste("LCI: ", x[(0.025*25000)]))
print(paste("UCI: ", x[(0.975*25000)]))
}

melt.mod <- melt(mod, measure.vars=c("1981-1988", "1989-2013", "2014-2017"))
names(melt.mod)[3] <- "era"
melt.mod$covar <- "SST"

# and plot
# make a SST-only plot
ggplot(melt.mod, aes(x=value, fill=era)) +
  theme_bw() + 
  geom_density(alpha=0.6) +
  geom_vline(xintercept = 0, lty=2) +
  scale_fill_manual(values = cb[c(4, 6, 2)]) +
  theme(legend.title = element_blank(), legend.position = c(0.8, 0.8)) +
  xlab("Slope") +
  xlim(-8,7)

ggsave("all plankton era sst slopes.png", width=5, height=4, units="in")
```

